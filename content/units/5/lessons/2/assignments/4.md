[//]: <> (name: Beat and Chord Retrieval Endpoints )
[//]: <> (author: Joe Turner)
[//]: <> (type: code along)
[//]: <> (time: 3 hours)

# Adding an audio analysis endpoint

In this lesson you will be adding one final endpoint which will analyse the audio from the songs you upload and return the data to the application.

## The analysis endpoint

In the *chords/analysis.py* file there is a pre-written function called `analyse`, which takes the path to a file as an argument, and returns a dictionary containg the results of the analysis.

In your *chords/api.py* file, add a GET endpoint for `/api/songs/<id>/analysis`.  The endpoint should:

* Check whether a song with the correct ID exists
* Get the filename of the song from the database
* Call the analyse function, passing in the path of the uploaded file
* Return the results of the analysis as a JSON object

## Testing it out

When your endpoint is complete run your code using `python run.py` and visit the app again.  Now, when you select a song it should analyse the audio (which may take a few seconds), and add markers to the player indicating the position of the chord changes and the tempo of the song.  As you play the song you should see the chords displayed, along with an indication of the tempo.  If you've made it this far then congratulations - you've just made your first single-page app!

## Extension task

Try adding some extra information to the user interface.  The tempo of the song may be a good place to start as we already calculate it in our analysis of the audio.  Take a look through the *chords/chords/static/js/main.js* file to try to find out where you will need to add extra code to get the correct information to display.

